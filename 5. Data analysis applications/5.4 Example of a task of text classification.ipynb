{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов: спам-фильтр для SMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо построить классификатор текстов по данным открытого датасета с SMS-сообщениями, размеченными на спам (\"spam\") и не спам (\"ham\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузка [данных](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\Xiaomi\\Desktop\\Data Science\\5. Прикладные задачи анализа данных'\n",
    "file_name = r'SMSSpamCollection.txt'\n",
    "file_path = folder_path + '\\\\' + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r', encoding='charmap') as new_file:\n",
    "    data = new_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление пустого элемента\n",
    "del data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 5574\n"
     ]
    }
   ],
   "source": [
    "print('data:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Подготовка списков для дальнейшей работы.**\n",
    "\n",
    "1 - спам, 0 - \"не спам\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list()\n",
    "labels = list()\n",
    "\n",
    "for message in data:\n",
    "    \n",
    "    text = message.split('\\t')\n",
    "    \n",
    "    messages.append(text[1])\n",
    "    \n",
    "    if text[0] == 'ham':\n",
    "        labels.append(0)\n",
    "        \n",
    "    elif text[0] == 'spam':\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages: 5574\n",
      "labels 5574\n"
     ]
    }
   ],
   "source": [
    "print('messages:', len(messages))\n",
    "print('labels', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([4827,  747], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(ar=labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Подготовка матрицы признаков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модули для построения признаков на текстах\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Оценка качества классификации текстов при использовании логистической регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# линейные классификаторы\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# модуль кросс-валидации\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318851880515823"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(solver='lbfgs', random_state=2), X, labels, scoring='f1', cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Обучение классификатора.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs', random_state=2).fit(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Проверка работы классификатора на примерах сообщений (1,1,0,0,0).**\n",
    "\n",
    "0 - не спам, 1 - спам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messges = [\n",
    "    \"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "    \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "    \"Have you visited the last lecture on physics?\",\n",
    "    \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "    \"Only 99$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test_messges)\n",
    "print(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Сравнение качества классификации при добавлении в признаки n-граммы для разных диапазонов n - только биграмм, только триграмм, всего вместе - униграммы, биграммы и триграммы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модуль пайплайн\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращает пайплайн для текстовой классификации\n",
    "def text_classifier(vectorizer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (2, 2)\n",
      "0.816782323945987\n",
      "\n",
      "ngram_range (3, 3)\n",
      "0.7250161555467377\n",
      "\n",
      "ngram_range (1, 3)\n",
      "0.9236977114588596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in [(2,2), (3,3), (1,3)]:\n",
    "    print('ngram_range',param)\n",
    "    print(cross_val_score(text_classifier(CountVectorizer(ngram_range=param), LogisticRegression(solver='lbfgs', random_state=2)), messages, labels, scoring='f1', cv=10).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистики по биграммам и триграммам намного меньше, поэтому классификатор только на них работает хуже. В то же время это не ухудшает результат сколько-нибудь существенно, если добавлять их вместе с униграммами, т.к. за счет регуляризации линейный классификатор не склонен сильно переобучаться на этих признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Сравнение качества классификации при добавлении в признаки n-граммы для разных диапазонов n - только биграмм, только триграмм, всего вместе - униграммы, биграммы и триграммы при использовании вместо логистической регрессии наивного Байеса.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (2, 2)\n",
      "0.9323117762969109\n",
      "\n",
      "ngram_range (3, 3)\n",
      "0.871265305963816\n",
      "\n",
      "ngram_range (1, 3)\n",
      "0.9479591028904112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Не верно!!!')\n",
    "\n",
    "for param in [(2,2), (3,3), (1,3)]:\n",
    "    print('ngram_range',param)\n",
    "    print(cross_val_score(text_classifier(CountVectorizer(ngram_range=param), MultinomialNB()), messages, labels, scoring='f1', cv=10).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По какой-то причине обучение наивного байесовского классификатора через Pipeline происходит с ошибкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (2, 2)\n",
      "0.6434846004951214\n",
      "\n",
      "ngram_range (3, 3)\n",
      "0.37758088051034894\n",
      "\n",
      "ngram_range (1, 3)\n",
      "0.8863675289084053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in [(2,2), (3,3), (1,3)]:\n",
    "    print('ngram_range',param)\n",
    "    vectorizer = CountVectorizer(ngram_range=param)\n",
    "    X = vectorizer.fit_transform(messages)\n",
    "    classifier = MultinomialNB().fit(X, labels)\n",
    "    print(cross_val_score(classifier, X, labels, scoring='f1', cv=10).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байес значительно сильнее линейного классификатора страдает от нехватки статистики по биграммам и триграммам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Используем в логистической регрессии в качестве признаков Tf*idf из TfidfVectorizer на униграммах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модули для построения признаков на текстах\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519515251846876"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(messages)\n",
    "cross_val_score(LogisticRegression(solver='lbfgs', random_state=2), X, labels, scoring='f1', cv=10).mean()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
